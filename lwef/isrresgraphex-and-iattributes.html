<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>ISRResGraphEx and IAttributes</title>
<style>
table th { border: 1px solid; }
table td { border: 1px solid; }
</style>
</head>
<body>
<hr />
<h2>title: ISRResGraphEx and IAttributes
description: ISRResGraphEx and IAttributes
ms.assetid: 6eb37da1-5252-4c41-891c-c19cca6fb7d1
ms.topic: article
ms.date: 05/31/2018</h2>
<h1>ISRResGraphEx and IAttributes</h1>
<p>[Microsoft Agent is deprecated as of Windows 7, and may be unavailable in subsequent versions of Windows.]</p>
<p>The results objects returned by the engine must support the ISRResGraphEx interface and the IAttributes interface. Merely supporting the ISRResGraphEx interface is enough to enable the sound editor to provide word break information, but does not provide the necessary support for phoneme information.</p>
<p>The sound editor requires that engines also support a special DWord attribute, <strong>SRATTR_PHONESEG</strong>. The editor queries the engines to see IAttributes interface and attempts to set the <strong>SRATTR_PHONESEG</strong> to 1. If that call succeeds, the sound editor assumes that the engine's results will support the gathering of phoneme-segmentation information from results object.</p>
<p><code>#define    SRATTR_PHONESEG    MAKELONG (1, SRVEN_MICROSOFT)</code></p>
<p>When a results object is transmitted to the sound editor, it queries that object for its implementation of ISRResGraphEx. ISRResGraphEx contains a member function, DataGet, with type signature</p>
<p><code>HRESULT  DataGet  (DWord, dwID, GUID gAttrib, SDATA *psData)</code></p>
<p>Where <strong>dwID</strong> is the identifier of the graph object, <strong>gAttrib</strong> is a GUID corresponding to the attribute sought, and <strong>psData</strong> is a pointer to an SDATA object containing the data returned. The engine is responsible for allocating the data stored in <strong>psData</strong> through <a href="/windows/desktop/api/combaseapi/nf-combaseapi-cotaskmemalloc"><strong>CoTaskMemAlloc</strong></a>. The calling application (in this case the sound editor) is responsible for freeing it through <a href="/windows/desktop/api/combaseapi/nf-combaseapi-cotaskmemfree"><strong>CoTaskMemFree</strong></a> when it is finished.</p>
<p>DataGet is required to recognize three predefined GUIDs, which are listed in the SAPI documentation. An engine which returns a success code to the call to <strong>DWORDSet(SRATTR_PHONESEG, 1)</strong> is also required to recognize a specific GUID, <strong>SRGARC_PHONEMESEGMENTATION</strong>, when called with a <strong>dwID</strong> that corresponds to an edge in the graph.</p>
<p><code>DEFINE_GUID(SRGARC_PHONMESEGMENTATION, 0xd05405b0, 0x1db1, 0x11d2, 0x94, 0x2, 0x0, 0xc0, 0x4f, 0x8e, 0xf4, 0x8f);</code></p>
<p>When the call returns, <strong>psData</strong> should point to an array of DWORD-aligned structure of type <strong>PHONESEG</strong>, defined by:</p>
<pre lang="syntax"><code>typedef struct tagSRPHONESEG {
   DWORD   dwSize;       // Size of the SRPHONESEG structure + phone data
   QWORD   qwStartTime;  // SAPI timestamp of the start of the seqment
   â€¦QWORD   qwEndTime;    // SAPI timestamp of the end of the seqment
   int      nScore;      // The segment's score
   WCHAR   aPhones[0];   // Array of phone(s) making up the segment
} SRPHONESEG,  *PSRPHONESEG;
</code></pre>
<p>where <strong>qwStartTime</strong> and <strong>qwEndTime</strong> point to the beginning and end of each phoneme making up the word covered by the edge, and <strong>aPhones</strong> is an array of Unicode characters corresponding to the IPA representation of the phone, which were produced in this segment. (In some languages, there are phonemes which are spelled with more than one IPA phoneme. In English, for instance, the &quot;long I&quot; sound in the word &quot;live&quot; is actually a diphthong, made up of two simpler phonemes concatenated together.) The <strong>aPhones</strong> array should be zero terminated and padded at the end to make each <strong>SRPHONESEG</strong> structure in the array an even multiple of four bytes long.</p>
<p>For example, suppose the word spoken on arc 4 was &quot;made&quot;. Then the call to DataGet(4, <strong>SRGARC_PHONEMESEGMENTATION</strong>, &amp;sd) might return an array of three phoneme segments, /m/ running from <strong>qwStartTime</strong>=328434 bytes to <strong>qwEndTime</strong>=330354 bytes, /1e/ running from <strong>qwStartTime</strong>=330354 bytes to <strong>qwEndTime</strong>=344114 bytes, and /d/ running from <strong>qwStartTime</strong>=344114 bytes to <strong>qwEndTime</strong>=347314 bytes. These would be presented as a packed array of three <strong>SRPHONESEG</strong> structures of sizes 28, 32, and 28 bytes, respectively. Notice that there is some padding at the end of the middle <strong>SRPHONESEG</strong> structure, so that the next item in the array starts at a 4-byte boundary.</p>
<p>The SAPI 4.0 SDK includes a tool (SRFunc) for testing compliance with the SAPI 4.0 spec. Included in that tool is a test for compliance with this set of interfaces. The source code for that tool is a good place to start in order to understand how these interfaces will interact with the sound editor, and to debug the interfaces during development.</p>
<p>Â </p>
<p>Â </p>
</body>
