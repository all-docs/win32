<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>Listen, Dont Just Recognize</title>
<style>
table th { border: 1px solid; }
table td { border: 1px solid; }
</style>
</head>
<body>
<hr />
<h2>title: Listen, Dont Just Recognize
description: Listen, Dont Just Recognize
ms.assetid: 74bb2122-98c1-4a51-b894-93e1481aa46b
ms.topic: article
ms.date: 05/31/2018</h2>
<h1>Listen, Dont Just Recognize</h1>
<p>[Microsoft Agent is deprecated as of Windows 7, and may be unavailable in subsequent versions of Windows.]</p>
<p>Successful communication involves more than recognition of words. The process of dialogue implies exchanging cues to signal turn-taking and understanding. Characters can improve conversational interfaces by providing cues like head tilts, nods, or shakes to indicate when the speech engine is in the listening state and when something is recognized. For example, Microsoft Agent plays animations assigned to the <strong>Listening</strong> state when a user presses the push-to-talk listening key and animations assigned to the <strong>Hearing</strong> state when an utterance is detected. When defining your own character, make sure you create and assign appropriate animations to these states. For more information on designing characters, see <a href="designing-characters-for-microsoft-agent.html">Designing Characters for Microsoft Agent</a>.</p>
<p>In addition to non-verbal cues, a conversation involves a common context between the conversing parties. Similarly, speech input scenarios with characters are more likely to succeed when the context is well established. Establishing the context enables you to better interpret similar-sounding phrases like &quot;check's in the mail&quot; and &quot;check my mail.&quot; You may also want to enable the user to query the context by providing a command, such as &quot;Help&quot; or &quot;Where am I,&quot; to which you respond by restating the current context, such as the last action your application performed.</p>
<p>Microsoft Agent provides interfaces that enable you access the best match and the two next best alternatives returned by the speech recognition engine. In addition, you can access confidence scores for all matches. You can use this information to better determine what was spoken. For example, if the confidence scores of the best match and first alternative are close, it may indicate that the speech engine had difficulty discerning the difference between them. In such a case, you may want to ask the user to repeat or rephrase the request in an effort to improve performance. However, if the best match and first or second alternatives return the same command, it strengthens the indication of the correct recognition.</p>
<p>The nature of a conversation or dialogue implies that there should be a response to spoken input. Therefore, a user's input should always be responded to with verbal or visual feedback that indicates an action was performed or a problem was encountered, or provides an appropriate reply.</p>
<p>Â </p>
<p>Â </p>
</body>
