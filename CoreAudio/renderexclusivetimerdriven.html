<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>RenderExclusiveTimerDriven</title>
<style>
table th { border: 1px solid; }
table td { border: 1px solid; }
</style>
</head>
<body>
<hr />
<h2>description: This sample application uses the Core Audio APIs to render audio data to an output device specified by the user. This sample demonstrates timer-driven buffering for a rendering client in exclusive mode.
ms.assetid: 9dcfccd2-a709-4b4e-bbb3-4c68a15cce03
title: RenderExclusiveTimerDriven
ms.topic: article
ms.date: 05/31/2018</h2>
<h1>RenderExclusiveTimerDriven</h1>
<p>This sample application uses the Core Audio APIs to render audio data to an output device specified by the user. This sample demonstrates timer-driven buffering for a rendering client in exclusive mode. For an exclusive-mode stream, the client shares the endpoint buffer with the audio device.</p>
<p>This topic contains the following sections.</p>
<ul>
<li><a href="#description">Description</a></li>
<li><a href="#requirements">Requirements</a></li>
<li><a href="#downloading-the-sample">Downloading the Sample</a></li>
<li><a href="#building-the-sample">Building the Sample</a></li>
<li><a href="#view-the-sample-files">View the Sample Files</a></li>
<li><a href="#related-topics">Related topics</a></li>
</ul>
<h2>Description</h2>
<p>This sample demonstrates the following features.</p>
<ul>
<li><a href="mmdevice-api.html">MMDevice API</a> for multimedia device enumeration and selection.</li>
<li>WASAPI for stream management operations.</li>
</ul>
<h2>Requirements</h2>
<table>
<thead>
<tr>
<th>Product</th>
<th>Version</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://msdn.microsoft.com/windowsvista/bb980924.aspx">Windows SDK</a></td>
<td>WindowsÂ 7</td>
</tr>
<tr>
<td>Visual Studio</td>
<td>2008</td>
</tr>
</tbody>
</table>
<p>Â </p>
<h2>Downloading the Sample</h2>
<p>This sample is available in the following locations.</p>
<table>
<thead>
<tr>
<th>Location</th>
<th>Path/URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>Windows SDK</td>
<td>\Program Files\Microsoft SDKs\Windows\v7.0\Samples\Multimedia\Audio\RenderExclusiveTimerDriven\...</td>
</tr>
</tbody>
</table>
<p>Â </p>
<h2>Building the Sample</h2>
<p>To build the RenderExclusiveTimerDriven sample, use the following steps:</p>
<ol>
<li>Open the CMD shell for the Windows SDK and change to the RenderExclusiveTimerDriven sample directory.</li>
<li>Run the command <code>start WASAPIRenderExclusiveTimerDriven.sln</code> in the RenderExclusiveTimerDriven directory to open the WASAPIRenderExclusiveTimerDriven project in the Visual Studio window.</li>
<li>From within the window, select the <strong>Debug</strong> or <strong>Release</strong> solution configuration, select the <strong>Build</strong> menu from the menu bar, and select the <strong>Build</strong> option. If you do not open Visual Studio from the CMD shell for the SDK, Visual Studio will not have access to the SDK build environment. In that case, the sample will not build unless you explicitly set environment variable MSSdk, which is used in the project file, WASAPIRenderExclusiveTimerDriven.vcproj.</li>
</ol>
<h2>View the Sample Files</h2>
<p>If you build the demo application successfully, an executable file, WASAPIRenderExclusiveTimerDriven.exe, is generated. To run it, type <code>WASAPIRenderExclusiveTimerDriven</code> in a command window followed by required or optional arguments. The following example shows how to run the sample by a specifying playback duration on the default console device.</p>
<p><code>WASAPIRenderExclusiveTimerDriven.exe -d 20 -console</code></p>
<p>The following table shows the arguments.</p>
<table>
<thead>
<tr>
<th>Argument</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>-?</td>
<td>Shows help.</td>
</tr>
<tr>
<td>-h</td>
<td>Shows help.</td>
</tr>
<tr>
<td>-f</td>
<td>Sine wave frequency in Hz.</td>
</tr>
<tr>
<td>-l</td>
<td>Audio render latency in milliseconds.</td>
</tr>
<tr>
<td>-d</td>
<td>Sine wave duration in seconds.</td>
</tr>
<tr>
<td>-m</td>
<td>Disables the use of MMCSS.</td>
</tr>
<tr>
<td>-console</td>
<td>Use the default console device.</td>
</tr>
<tr>
<td>-communications</td>
<td>Use the default communication device.</td>
</tr>
<tr>
<td>-multimedia</td>
<td>Use the default multimedia device.</td>
</tr>
<tr>
<td>-endpoint</td>
<td>Use the endpoint identifier specified in the switch value.</td>
</tr>
</tbody>
</table>
<p>Â </p>
<p>If the application is run without arguments, it enumerates the available devices and prompts the user to select a device for the rendering session. After the user specifies a device, the application renders a sine wave at 440 Hz for 10 seconds. These values can be modified by specifying -f and -d switch values.</p>
<p>RenderExclusiveTimerDriven demonstrates timer-driven buffering. In this mode, the client must wait for a period of time (half the latency, specified by the -d switch value, in milliseconds). When the client wakes up, half way through the processing period, it pulls the next set of samples from the engine. Before each processing pass in the buffering loop, the client must find out the amount of data to render so that the data does not overrun the buffer.</p>
<p>Audio data to be played on the specified device can be processed by enabling event-driven buffering. This mode is demonstrated in the RenderExclusiveTimerDriven sample.</p>
<p>For more information about rendering a stream, see <a href="rendering-a-stream.html">Rendering a Stream</a>.</p>
<h2>Related topics</h2>
<!-- raw HTML omitted -->
<p><a href="sdk-samples-that-use-the-core-audio-apis.html">SDK Samples That Use the Core Audio APIs</a></p>
<!-- raw HTML omitted -->
<p>Â </p>
<p>Â </p>
</body>
