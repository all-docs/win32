<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>Using a Communication Device</title>
<style>
table th { border: 1px solid; }
table td { border: 1px solid; }
</style>
</head>
<body>
<hr />
<h2>description: In WindowsÂ 7, the Windows multimedia control panel, Mmsys.cpl, provides a new Communications tab.
ms.assetid: bec2127d-fb82-436d-beee-d43e8fef5c35
title: Using a Communication Device
ms.topic: article
ms.date: 05/31/2018</h2>
<h1>Using a Communication Device</h1>
<p>In WindowsÂ 7, the Windows multimedia control panel, Mmsys.cpl, provides a new <strong>Communications</strong> tab. This tab contains options that enables a user to set options that defines how the system manages a <em>communication device</em>. A communication device is used primarily for placing or receiving telephone calls on the computer. For a computer that has only one rendering device (speaker) and one capture device (microphone), these audio devices also act as the default communication devices. When a user connects a new device, such as a USB headset, the system performs automatic device role detection by looking up the configuration settings that are populated by the OEM. If the system determines a device to be best suited for communication purposes, the system assigns the <strong>eCommunications</strong> role to the device. For these devices, the WindowsÂ 7 Mmsys.cpl provides the option <strong>Default Communication Device</strong> that enables a user to select a communication device each for audio rendering (<strong>Playback</strong> tab) and audio capturing (<strong>Recording</strong> tab). The system performs automatic role detection but does not set a particular device to be used for communications. This must be done by the user. The new <strong>eCommunications</strong> role lets an application distinguish between a device that is chosen by the user for handling phone calls and a device to be used as a multimedia device (music playback). For example, if the user has a headset and a speaker connected to the computer, the system assigns the <strong>eConsole</strong> role to the speaker and the <strong>eCommunications</strong> role to the headset. After the user selects the headset to be used as the communication device, to develop a communication application, you can target the headset specifically for rendering an audio stream. An application the user cannot change the device role assigned by the system. For more information about device roles, see <a href="device-roles.html">Device Roles</a>.</p>
<p>Communication applications, such as VoIP and Unified Communication applications, place and receive phone calls through a computer. For example, a VoIP application might assign a stream that contains the ring-in notification to the endpoint of a communication device set for rendering audio streams. In addition, the application might open the voice input and output streams on the capture and rendering endpoint devices that are set as communication devices.</p>
<p>To integrate communication capabilities into your applications, you can use:</p>
<ul>
<li><a href="mmdevice-api.html">MMDevice API</a>â€”to get a reference to the endpoint of the communication device.</li>
<li><a href="wasapi.html">WASAPI</a>â€”to render and capture audio streams through the communication device. The operating system considers the stream opened on a communication device to be a <em>communication stream</em>.</li>
</ul>
<p>The communication application enumerates devices and provides stream management for a communication stream (rendering or capture) stream in the same manner as it would manage a non-communication stream by using the Core Audio APIs.</p>
<p>One of the features that you can integrate in your communication application is <em>ducking</em> or <em>stream attenuation</em>. This behavior defines what must happen to other sounds when a communication stream is opened, such as when a phone call is received on the communication device. The system might mute or lower the audio volume of the non-communication stream depending on the user's choice. The audio system generates ducking events when a communication stream is opened or closed for rendering or capturing streams. By default, the operating system provides a default ducking experience. A media application can replace the default behavior and handle these events itself to provide a customized ducking experience.</p>
<p>The following sections describe how to use Core Audio APIs to provide a custom ducking experience.</p>
<ul>
<li><a href="stream-attenuation.html">Default Ducking Experience</a></li>
<li><a href="disabling-the-ducking-experience.html">Disabling the Default Ducking Experience</a></li>
<li><a href="providing-a-custom-ducking-experience.html">Providing a Custom Ducking Behavior</a></li>
<li><a href="handling-audio-ducking-events-from-communication-devices.html">Implementation Considerations for Ducking Notifications</a></li>
<li><a href="getting-ducking-events-from-a-communication-device.html">Getting Ducking Events</a></li>
</ul>
<h3>Getting a Reference to the Communication Device Endpoint</h3>
<p>To use the communication device, a direct WASAPI client must enumerate the devices by using the device enumerator. Get a reference to the endpoint of the default communication device by calling <a href="/windows/desktop/api/Mmdeviceapi/nf-mmdeviceapi-immdeviceenumerator-getdefaultaudioendpoint"><strong>IMMDeviceEnumerator::GetDefaultAudioEndpoint</strong></a>. In this call, the application must specify <strong>eCommunications</strong> in the <em>Role</em> parameter to restrict the device enumeration to communication devices. After you get a reference to the device endpoint for the device, you can activate the services that are scoped for the endpoint by calling <a href="/windows/desktop/api/Mmdeviceapi/nf-mmdeviceapi-immdevice-activate"><strong>IMMDevice::Activate</strong></a>. For example, you can pass the <strong>IID_IAudioClient</strong> service identifier to activate an audio client object and use it for stream management, the <strong>IID_IAudioEndpointVolume</strong> identifier to get access to the volume controls of the communication device endpoint, or the <strong>IID_IAudioSessionManager</strong> identifier to activate the session manager that enables you to interact with the policy engine of the endpoint. For information about stream operations, see <a href="stream-management.html">Stream Management</a>.</p>
<p>By using the <a href="/windows/desktop/api/Mmdeviceapi/nn-mmdeviceapi-immdevice"><strong>IMMDevice</strong></a> reference, you can also access the property store for the device endpoint. These property values, such as device friendly name and manufacturer name, are populated by the OEM and enable an application to determine the characteristics of a communication device. For more information, see <a href="device-properties.html">Device Properties</a>.</p>
<p>The following example code gets a reference to the endpoint of the default communication device for rendering an audio stream.</p>
<pre lang="C++"><code>IMMDevice *defaultDevice = NULL;

hr = CoCreateInstance(__uuidof(MMDeviceEnumerator), NULL,
            CLSCTX_INPROC_SERVER, 
            __uuidof(IMMDeviceEnumerator), 
            (LPVOID *)&amp;deviceEnumerator);

hr = deviceEnumerator-&gt;GetDefaultAudioEndpoint(eRender, 
            eCommunications, &amp;defaultDevice);
</code></pre>
<h2>Related topics</h2>
<!-- raw HTML omitted -->
<p><a href="stream-management.html">Stream Management</a></p>
<!-- raw HTML omitted -->
<p>Â </p>
<p>Â </p>
</body>
