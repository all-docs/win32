<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>CaptureSharedEventDriven</title>
<style>
table th { border: 1px solid; }
table td { border: 1px solid; }
</style>
</head>
<body>
<hr />
<h2>description: This sample application uses the Core Audio APIs to capture audio data from an input device specified by the user and writes it to a uniquely named .wav file in the current directory. This sample demonstrates event-driven buffering.
ms.assetid: 6ff3bc23-550e-41b7-b37c-35d552b29e20
title: CaptureSharedEventDriven
ms.topic: article
ms.date: 05/31/2018</h2>
<h1>CaptureSharedEventDriven</h1>
<p>This sample application uses the Core Audio APIs to capture audio data from an input device specified by the user and writes it to a uniquely named .wav file in the current directory. This sample demonstrates event-driven buffering.</p>
<p>This topic contains the following sections.</p>
<ul>
<li><a href="#description">Description</a></li>
<li><a href="#requirements">Requirements</a></li>
<li><a href="#downloading-the-sample">Downloading the Sample</a></li>
<li><a href="#building-the-sample">Building the Sample</a></li>
<li><a href="#running-the-sample">Running the Sample</a></li>
<li><a href="#related-topics">Related topics</a></li>
</ul>
<h2>Description</h2>
<p>This sample demonstrates the following features.</p>
<ul>
<li><a href="mmdevice-api.html">MMDevice API</a> for multimedia device enumeration and selection.</li>
<li><a href="wasapi.html">WASAPI</a> for stream management operations such as starting and stopping the stream, and stream switching.</li>
</ul>
<h2>Requirements</h2>
<table>
<thead>
<tr>
<th>Product</th>
<th>Version</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://msdn.microsoft.com/windowsvista/bb980924.aspx">Windows SDK</a></td>
<td>WindowsÂ 7</td>
</tr>
<tr>
<td>Visual Studio</td>
<td>2008</td>
</tr>
</tbody>
</table>
<p>Â </p>
<h2>Downloading the Sample</h2>
<p>This sample is available in the following locations.</p>
<table>
<thead>
<tr>
<th>Location</th>
<th>Path/URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>Windows SDK</td>
<td>\Program Files\Microsoft SDKs\Windows\v7.0\Samples\Multimedia\Audio\CaptureSharedEventDriven\...</td>
</tr>
</tbody>
</table>
<p>Â </p>
<h2>Building the Sample</h2>
<p>To build the CaptureSharedEventDriven sample, use the following steps:</p>
<ol>
<li>Open the CMD shell for the Windows SDK and change to the CaptureSharedEventDriven sample directory.</li>
<li>Run the command <code>start WASAPICaptureSharedEventDriven.sln</code> in the CaptureSharedEventDriven directory to open the WASAPICaptureSharedEventDriven project in the Visual Studio window.</li>
<li>From within the window, select the <strong>Debug</strong> or <strong>Release</strong> solution configuration, select the <strong>Build</strong> menu from the menu bar, and select the <strong>Build</strong> option. If you do not open Visual Studio from the CMD shell for the SDK, Visual Studio will not have access to the SDK build environment. In that case, the sample will not build unless you explicitly set environment variable MSSdk, which is used in the project file, WASAPICaptureSharedEventDriven.vcproj.</li>
</ol>
<h2>Running the Sample</h2>
<p>If you build the demo application successfully, an executable file, WASAPICaptureSharedEventDriven.exe, is generated. To run it, type <code>WASAPICaptureSharedEventDriven</code> in a command window followed by required or optional arguments. The following example shows how to run the sample by specifying capture duration on the default multimedia device.</p>
<p><code>WASAPICaptureSharedEventDriven.exe -d 20 -multimedia</code></p>
<p>The following table shows the arguments.</p>
<table>
<thead>
<tr>
<th>Argument</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>-?</td>
<td>Shows help.</td>
</tr>
<tr>
<td>-h</td>
<td>Shows help.</td>
</tr>
<tr>
<td>-l</td>
<td>Audio capture latency in milliseconds.</td>
</tr>
<tr>
<td>-d</td>
<td>Audio capture duration in seconds.</td>
</tr>
<tr>
<td>-m</td>
<td>Disables the use of MMCSS.</td>
</tr>
<tr>
<td>-console</td>
<td>Use the default console device.</td>
</tr>
<tr>
<td>-communications</td>
<td>Use the default communication device.</td>
</tr>
<tr>
<td>-multimedia</td>
<td>Use the default multimedia device.</td>
</tr>
<tr>
<td>-endpoint</td>
<td>Use the endpoint identifier specified in the switch value.</td>
</tr>
</tbody>
</table>
<p>Â </p>
<p>If the application is run without arguments, it enumerates the available devices and prompts the user to select a device for the capture session. The default console, communication, and multimedia devices are listed followed by devices and the endpoint identifiers. If no duration is specified, the audio stream from the specified device is captured for 10 seconds. The application writes the captured data to a uniquely named .wav file.</p>
<p>CaptureSharedEventDriven demonstrates event-driven buffering. The audio client instantiated for this sample is configured to run in shared mode and the client's processing of the audio buffer is made event driven by setting the <strong>AUDCLNT_STREAMFLAGS_EVENTCALLBACK</strong> flag in the call to <a href="/windows/desktop/api/Audioclient/nf-audioclient-iaudioclient-initialize"><strong>IAudioClient::Initialize</strong></a>. The sample shows how the client must provide an event handle to the system by calling the <a href="/windows/desktop/api/Audioclient/nf-audioclient-iaudioclient-seteventhandle"><strong>IAudioClient::SetEventHandle</strong></a> method. After the capture session begins and the stream starts, the audio engine signals the supplied event handle to notify the client each time a buffer becomes ready for the client to process. The audio data can also be processed in a timer-driven loop. This mode is demostrated in the <a href="capturesharedtimerdriven.html">CaptureSharedTimerDriven</a> sample.</p>
<h2>Related topics</h2>
<!-- raw HTML omitted -->
<p><a href="sdk-samples-that-use-the-core-audio-apis.html">SDK Samples That Use the Core Audio APIs</a></p>
<!-- raw HTML omitted -->
<p>Â </p>
<p>Â </p>
</body>
