<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>Device Roles for DirectShow Applications</title>
<style>
table th { border: 1px solid; }
table td { border: 1px solid; }
</style>
</head>
<body>
<hr />
<h2>description: Device Roles for DirectShow Applications
ms.assetid: 54f42bda-b4a0-465c-9ce6-9102d2908776
title: Device Roles for DirectShow Applications
ms.topic: article
ms.date: 05/31/2018</h2>
<h1>Device Roles for DirectShow Applications</h1>
<blockquote>
<p>[!Note]<br />
The <a href="mmdevice-api.html">MMDevice API</a> supports device roles. However, the user interface in Windows Vista does not implement support for this feature. User interface support for device roles might be implemented in a future version of Windows. For more information, see <a href="device-roles-in-windows-vista.html">Device Roles in Windows Vista</a>.</p>
</blockquote>
<p>Â </p>
<p>The DirectShow API does not provide a means for an application to select the <a href="audio-endpoint-devices.html">audio endpoint device</a> that is assigned to a particular <a href="device-roles.html">device role</a>. However, in Windows Vista, the core audio APIs can be used in conjunction with a DirectShow application to enable device selection based on device role. With the help of the core audio APIs, the application can:</p>
<ul>
<li>Identify the audio endpoint device that the user has assigned to a particular device role.</li>
<li>Create a DirectShow audio rendering filter with an <a href="/windows/desktop/api/strmif/nn-strmif-ibasefilter"><strong>IBaseFilter</strong></a> interface that encapsulates the audio endpoint device.</li>
<li>Build a DirectShow graph that incorporates the filter.</li>
</ul>
<p>For more information about DirectShow and <a href="/windows/desktop/api/strmif/nn-strmif-ibasefilter"><strong>IBaseFilter</strong></a>, see the Windows SDK documentation.</p>
<p>The following code example shows how to create a DirectShow audio rendering filter that encapsulates the rendering endpoint device that is assigned to a particular device role:</p>
<pre lang="C++"><code>//-----------------------------------------------------------
// Create a DirectShow audio rendering filter that
// encapsulates the audio endpoint device that is currently
// assigned to the specified device role.
//-----------------------------------------------------------
#define EXIT_ON_ERROR(hres)  \
              if (FAILED(hres)) { goto Exit; }
#define SAFE_RELEASE(punk)  \
              if ((punk) != NULL)  \
                { (punk)-&gt;Release(); (punk) = NULL; }

// This application's audio session GUID
const GUID guidAudioSessionId = {
    0xb13ff52e, 0xa5cf, 0x4fca,
    {0x9f, 0xc3, 0x42, 0x26, 0x5b, 0x0b, 0x14, 0xfb}
};

HRESULT CreateAudioRenderer(ERole role, IBaseFilter** ppAudioRenderer)
{
    HRESULT hr = S_OK;
    IMMDeviceEnumerator *pEnumerator = NULL;
    IMMDevice *pDevice = NULL;

    if (ppAudioRenderer == NULL)
    {
        return E_POINTER;
    }

    // Activate the IBaseFilter interface on the
    // audio renderer with the specified role.
    hr = CoCreateInstance(CLSID_MMDeviceEnumerator,
                          NULL, CLSCTX_INPROC_SERVER,
                          __uuidof(IMMDeviceEnumerator),
                          (void**)&amp;pEnumerator);
    EXIT_ON_ERROR(hr)

    hr = pEnumerator-&gt;GetDefaultAudioEndpoint(eRender, role,
                                              &amp;pDevice);
    EXIT_ON_ERROR(hr)

    DIRECTX_AUDIO_ACTIVATION_PARAMS  daap;
    daap.cbDirectXAudioActivationParams = sizeof(daap);
    daap.guidAudioSession = guidAudioSessionId;
    daap.dwAudioStreamFlags = AUDCLNT_STREAMFLAGS_CROSSPROCESS;

    PROPVARIANT  var;
    PropVariantInit(&amp;var);

    var.vt = VT_BLOB;
    var.blob.cbSize = sizeof(daap);
    var.blob.pBlobData = (BYTE*)&amp;daap;

    hr = pDevice-&gt;Activate(__uuidof(IBaseFilter),
                           CLSCTX_ALL, &amp;var,
                           (void**)ppAudioRenderer);
    EXIT_ON_ERROR(hr)

Exit:
    SAFE_RELEASE(pEnumerator);
    SAFE_RELEASE(pDevice);
    return hr;
}
</code></pre>
<p>In the preceding code example, the CreateAudioRenderer function accepts a device role (eConsole, eMultimedia, or eCommunications) as an input parameter. The second parameter is a pointer through which the function writes the address of an <a href="/windows/desktop/api/strmif/nn-strmif-ibasefilter"><strong>IBaseFilter</strong></a> interface instance. In addition, the example shows how to use the <a href="/windows/desktop/api/Mmdeviceapi/nf-mmdeviceapi-immdevice-activate"><strong>IMMDevice::Activate</strong></a> method to assign the audio stream in the <strong>IBaseFilter</strong> instance to a cross-process audio session with an application-specific session GUID (specified by the <strong>guidAudioSessionId</strong> constant). The third parameter in the <strong>Activate</strong> call points to a structure that contains the session GUID and cross-process flag. If the user runs multiple instances of the application, then the audio streams from all the instances use the same session GUID and thus belong to the same session.</p>
<p>Alternatively, the caller can specify <strong>NULL</strong> as the third parameter in the <a href="/windows/desktop/api/Mmdeviceapi/nf-mmdeviceapi-immdevice-activate"><strong>Activate</strong></a> call to assign the stream to the default session as the process-specific session with session GUID value GUID_NULL. For more information, see <strong>IMMDevice::Activate</strong>.</p>
<h2>Related topics</h2>
<!-- raw HTML omitted -->
<p><a href="interoperability-with-legacy-audio-apis.html">Interoperability with Legacy Audio APIs</a></p>
<!-- raw HTML omitted -->
<p>Â </p>
<p>Â </p>
</body>
