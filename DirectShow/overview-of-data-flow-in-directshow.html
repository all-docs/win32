<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>Overview of Data Flow in DirectShow</title>
<style>
table th { border: 1px solid; }
table td { border: 1px solid; }
</style>
</head>
<body>
<hr />
<h2>description: Overview of Data Flow in DirectShow
ms.assetid: a1b30592-5106-44f5-8ee0-577573670167
title: Overview of Data Flow in DirectShow
ms.topic: article
ms.date: 4/26/2023
ms.custom: UpdateFrequency5</h2>
<h1>Overview of Data Flow in DirectShow</h1>
<p>[The feature associated with this page, <a href="/windows/win32/directshow/directshow">DirectShow</a>, is a legacy feature. It has been superseded by <a href="/uwp/api/Windows.Media.Playback.MediaPlayer">MediaPlayer</a>, <a href="/windows/win32/api/mfmediaengine/nn-mfmediaengine-imfmediaengine">IMFMediaEngine</a>, and <a href="/windows/win32/medfound/audio-video-capture-in-media-foundation">Audio/Video Capture in Media Foundation</a>. Those features have been optimized for Windows 10 and Windows 11. Microsoft strongly recommends that new code use <strong>MediaPlayer</strong>, <strong>IMFMediaEngine</strong> and <strong>Audio/Video Capture in Media Foundation</strong> instead of <strong>DirectShow</strong>, when possible. Microsoft suggests that existing code that uses the legacy APIs be rewritten to use the new APIs if possible.]</p>
<p>This section gives a broad overview of how data flow works in DirectShow. Details can be found in other sections of the documentation.</p>
<p>Data is held in buffers, which are simply arrays of bytes. Each buffer is wrapped by a COM object called a <em>media sample</em>, which implements the <a href="/windows/desktop/api/Strmif/nn-strmif-imediasample"><strong>IMediaSample</strong></a> interface. Samples are created by another type of object, called an allocator, which implements the <a href="/windows/desktop/api/Strmif/nn-strmif-imemallocator"><strong>IMemAllocator</strong></a> interface. An allocator is assigned for every pin connection, although two or more pin connections might share the same allocator. The following image illustrates this process.</p>
<p><img src="images/dataflow.png" alt="buffers, samples, and allocators" /></p>
<p>Each allocator creates a pool of media samples and allocates the buffers for each sample. Whenever a filter needs to fill a buffer with data, it requests a sample from the allocator by calling <a href="/windows/desktop/api/Strmif/nf-strmif-imemallocator-getbuffer"><strong>IMemAllocator::GetBuffer</strong></a>. If the allocator has any samples that are not currently in use by another filter, the <strong>GetBuffer</strong> method returns immediately with a pointer to the sample. If all of the allocator's samples are in use, the method blocks until a sample becomes available. When the method does return a sample, the filter puts data into the buffer, sets the appropriate flags on the sample (typically including a time stamp), and delivers the sample downstream.</p>
<p>When a renderer filter receives a sample, it checks the time stamp and holds onto the sample until the filter graph's reference clock indicates that the data should be rendered. After the filter renders the data, it releases the sample. The sample does not go back into the allocator's pool of samples until the sample's reference count is zero, meaning that every filter has released the sample. The following image illustrates this process.</p>
<p><img src="images/dataflow2.png" alt="decoder waiting for a free media sample" /></p>
<p>The upstream filter might run ahead of the renderer â€” that is, it might fill buffers faster than the renderer consumes them. Even so, samples do not get rendered early, because the renderer holds each until its presentation time. Moreover, the upstream filter will not overwrite buffers accidentally, because <strong>GetSample</strong> only returns samples that are not otherwise in use. The amount by which the upstream filter can run ahead is determined by the number of samples in the allocator's pool.</p>
<p>The previous diagram only shows one allocator, but typically there are several allocators per stream. Thus, when the renderer releases a sample, it can have a cascading effect. The following diagram shows a situation where a decoder holds a compressed video frame while it waits for the renderer to release a sample. A parser filter is also waiting for the decoder to release a sample.</p>
<p><img src="images/dataflow3.png" alt="two filters waiting for samples" /></p>
<p>When the renderer releases its sample, the decoder's pending call to <strong>GetBuffer</strong> returns. The decoder can then decode the compressed video frame and release the sample it was holding, thereby unblocking the parser's pending <strong>GetBuffer</strong> call.</p>
<h2>Related topics</h2>
<!-- raw HTML omitted -->
<p><a href="data-flow-in-the-filter-graph.html">Data Flow in the Filter Graph</a></p>
<!-- raw HTML omitted -->
<p>Â </p>
<p>Â </p>
</body>
